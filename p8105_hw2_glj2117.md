p8105_hw2_glj2117
================
2022-10-02

## Problem 1

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or recode function may be useful).

``` r
transit_data = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
    janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
 mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?

Answer the following questions using these data:

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway;
125st Lenox); the distinct function may be useful here. How many
stations are ADA compliant? What proportion of station entrances / exits
without vending allow entrance? Reformat data so that route number and
route name are distinct variables. How many distinct stations serve the
A train? Of the stations that serve the A train, how many are ADA
compliant?

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

## Problem 2

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel use reasonable variable names omit rows that do not include
dumpster-specific data round the number of sports balls to the nearest
integer and converts the result to an integer variable (using
as.integer)

``` r
mr_trash_wheel = read_excel("Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = round(sports_balls)) 
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel, and combine this with the Mr. Trash Wheel dataset
to produce a single tidy dataset. To keep track of which Trash Wheel is
which, you may need to add an additional variable to both datasets
before combining.

``` r
prof_trash_wheel = read_excel("Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  mutate(dataset = "prof")
 
mr_trash_wheel = mr_trash_wheel %>% 
  mutate(dataset = "mr") 

mr_trash_wheel = 
  mr_trash_wheel %>% 
  mutate("year" = as.numeric(year))
  

trash_data = 
  full_join(mr_trash_wheel, prof_trash_wheel) %>% 
  arrange(dumpster) %>% 
  mutate("as.numeric(year)" = NULL)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "dataset")

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of sports balls collected by Mr. Trash Wheel in 2020?

The joined dataset includes 641 observations on 547 dumpsters and
associated key variables, such as date of observation, weight and volume
of trash, and amount of plastic bottles, polystyrene, cigarette butts,
glass bottles, grocery bags, chip bags, and sports balls in the trash.
The `dataset` variable denotes if the data was collected by Mr. Trash
Wheel (mr) or Professor Trash Wheel (prof).The total weight of trash
collected by Professor Trash Wheel is 190.12. Additionally, the total
number of sports balls collected by Mr. Trash Wheel in 2020 was 856.

    ##Problem 3

    First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.


    ```r
    pols_month = read_csv("pols-month.csv") %>% 
      separate(col = 'mon', into = c('year', 'month', 'day'), sep = '-') %>% 
       mutate(month = recode(month, "01" = "January", "02" = "February", "03" = "March", "04" = "April", "05" = "May", "06" = "June", "07" = "July", "08" = "August", "09" = "September", "10" = "October", "11" = "November", "12" = "December")) %>% 
       mutate(day = NULL) %>%
       mutate(president = if_else(prez_dem == 0, "gop", "dem")) %>% 
       mutate(prez_gop = NULL, prez_dem = NULL) %>% 
       mutate(year = as.numeric(year)) %>% 
      unite("merged_date", year:month, remove = FALSE)

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp = read_csv("snp.csv") %>%
  separate(col = 'date', into = c('month', 'day', 'year'), sep = '/') %>% 
   mutate(month = recode(month, "1" = "January", "2" = "February", "3" = "March", "4" = "April", "5" = "May", "6" = "June", "7" = "July", "8" = "August", "9" = "September", "10" = "October", "11" = "November", "12" = "December")) %>% 
   mutate(day = NULL) %>%
  select("year", "month", "close") %>% 
  mutate(year_prefix = if_else(year < 22, 2000, 1900)) %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(year = year + year_prefix) %>% 
  mutate(year_prefix = NULL) %>% 
  unite("merged_date", year:month, remove = FALSE) %>% 
  mutate(year = NULL, month = NULL)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment = read_csv("unemployment.csv") %>% 
pivot_longer(Jan:Dec, 
names_to = 'month',
values_to = 'unemployment'
) %>% 
janitor::clean_names() %>% 
unite("merged_date", year:month, remove = FALSE) %>% 
mutate(year = NULL, month = NULL)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
snp_pols = 
  left_join(pols_month, snp, by = "merged_date") 

snp_pols_unemployment =
left_join(snp_pols, unemployment, by = "merged_date") %>% 
mutate(merged_date = NULL)
```

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

The original `pols_month` dataset included data about political seats by
party on a monthly basis from 1947-2015. In 1974, there are 5 months
where the value for “prez_gop” is 2 instead of the expected 0 or 1. This
is likely because there were two presidents during the single term
(Nixon and Ford). However, they were both republicans so should be coded
as prez_gop. The `snp` dataset included snp500 market close by month
from 1950-2015. The `unemployment` dataset included unemployment rates
by month from 1948-2015. The resulting combined dataset
(`snp_pols_unemployment`) includes 822 observations accross 11
variables. The data range from the years 1948-2015. Key variables
(besides date) include numbers of Republican governors, senators, and
representatives (`gov_gop`, `sen_gop`, `rep_gop` and the same metrics
for Democrat politicians (`gov_dem`, `sen_dem`, `rep_dem`). Additionaly,
the party of the `president`, SNP500 closing (`close`) and
`unemployment` rate are also included in this dataset.
